# íŒŒì¼ 2: FastMCP í´ë¼ì´ì–¸íŠ¸

import os
import argparse
import asyncio
from typing import Optional, Dict, Any, List

import google.generativeai as genai
from google.generativeai.types import FunctionDeclaration, Tool
from dotenv import load_dotenv

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemini API í‚¤ ì„¤ì •
genai.configure(api_key=os.getenv("GOOGLE_API_KEY", ''))

class CryptoAssistantClient:
    """
    'Intelligent Crypto Assistant' MCP ì„œë²„ì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤.
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ì„œë²„ì˜ ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    def __init__(self):
        self.session: Optional[ClientSession] = None
        self.model = genai.GenerativeModel(
            'gemini-2.5-flash', 
            system_instruction="ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì•”í˜¸í™”í ì‹œì¥ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì„¸ìš”."
        )
        self.chat = None
        self._streams_context = None
        self._session_context = None

    async def connect(self, server_url: str):
        """ì§€ì •ëœ URLì˜ MCP ì„œë²„ì— ì—°ê²°í•˜ê³  ì„¸ì…˜ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        print(f"...{server_url} ì— ì—°ê²° ì¤‘...")
        try:
            self._streams_context = streamablehttp_client(url=server_url, headers={})
            read_stream, write_stream, _ = await self._streams_context.__aenter__()
            self._session_context = ClientSession(read_stream, write_stream)
            self.session = await self._session_context.__aenter__()
            await self.session.initialize()
            print("âœ… ì„œë²„ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    def _remove_keys_recursively(self, obj: Any, keys_to_remove: List[str]) -> Any:
        """ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • í‚¤ë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤."""
        if isinstance(obj, dict):
            return {
                key: self._remove_keys_recursively(value, keys_to_remove)
                for key, value in obj.items() if key not in keys_to_remove
            }
        elif isinstance(obj, list):
            return [self._remove_keys_recursively(item, keys_to_remove) for item in obj]
        return obj

    def _mcp_tools_to_gemini_tools(self, mcp_tools: list) -> list[Tool]:
        """MCP ë„êµ¬ ìŠ¤í‚¤ë§ˆë¥¼ Geminiê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        gemini_tools = []
        # Gemini APIì™€ í˜¸í™˜ë˜ì§€ ì•Šì•„ ì œê±°í•´ì•¼ í•  ìŠ¤í‚¤ë§ˆ í•„ë“œ ëª©ë¡
        keys_to_remove = ['title', 'default']

        for tool in mcp_tools:
            # ì¬ê·€ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë¶ˆí•„ìš”í•œ í‚¤ë“¤ì„ ì œê±°
            gemini_compatible_schema = self._remove_keys_recursively(tool.inputSchema, keys_to_remove)

            function_declaration = FunctionDeclaration(
                name=tool.name,
                description=tool.description,
                parameters=gemini_compatible_schema,
            )
            gemini_tools.append(Tool(function_declarations=[function_declaration]))
        return gemini_tools

    async def process_query(self, query: str) -> str:
        """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ê³ , í•„ìš” ì‹œ ë„êµ¬ë¥¼ í˜¸ì¶œí•œ ë’¤ ìµœì¢… ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.session:
            raise ConnectionError("MCP ì„œë²„ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ì„œë²„ë¡œë¶€í„° ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ê°€ì ¸ì™€ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        response = await self.session.list_tools()
        available_tools = self._mcp_tools_to_gemini_tools(response.tools)

        if self.chat is None:
            self.chat = self.model.start_chat(enable_automatic_function_calling=False)

        print("...Geminiì—ê²Œ ì§ˆë¬¸ì„ ë³´ë‚´ëŠ” ì¤‘...")
        response = self.chat.send_message(query, tools=available_tools)

        response_part = response.parts[0]
        if response_part.function_call:
            fc = response_part.function_call
            tool_name = fc.name
            tool_args = dict(fc.args)

            print(f"ğŸ› ï¸ Geminiê°€ ë„êµ¬ í˜¸ì¶œì„ ìš”ì²­í•©ë‹ˆë‹¤: {tool_name}({tool_args})")
            tool_result_mcp = await self.session.call_tool(tool_name, tool_args)
            print("...ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ Geminiì—ê²Œ ë‹¤ì‹œ ë³´ë‚´ëŠ” ì¤‘...")

            # MCP ì„œë²„ì˜ ì‘ë‹µ(Streamable)ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œ
            tool_response_content = ""
            if isinstance(tool_result_mcp.content, list) and tool_result_mcp.content:
                tool_response_content = tool_result_mcp.content[0].text

            # ì¶”ì¶œí•œ ê²°ê³¼ë¥¼ Geminiì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
            response = self.chat.send_message(
                [{"function_response": {
                    "name": tool_name,
                    "response": {"content": tool_response_content},
                }}]
            )

        return response.text

    async def chat_loop(self):
        """ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë©”ì¸ ì±„íŒ… ë£¨í”„ì…ë‹ˆë‹¤."""
        print("\nğŸ¤– ì§€ëŠ¥í˜• ì•”í˜¸í™”í ë¹„ì„œ í´ë¼ì´ì–¸íŠ¸ì…ë‹ˆë‹¤.")
        print("   'quit' ë˜ëŠ” 'exit'ì„ ì…ë ¥í•˜ì—¬ ì¢…ë£Œí•˜ì„¸ìš”.")

        while True:
            try:
                query = input("\nğŸ‘¤ You: ").strip()
                if query.lower() in ["quit", "exit"]:
                    break
                if not query: continue

                response_text = await self.process_query(query)
                print(f"\nğŸ¤– Assistant:\n{response_text}")

            except Exception as e:
                print(f"\nğŸ’¥ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("   ëŒ€í™”ë¥¼ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.")
                self.chat = None # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™”

    async def cleanup(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì‹œ ì—°ê²°ì„ ì•ˆì „í•˜ê²Œ í•´ì œí•©ë‹ˆë‹¤."""
        if self._session_context: await self._session_context.__aexit__(None, None, None)
        if self._streams_context: await self._streams_context.__aexit__(None, None, None)
        print("\nğŸ‘‹ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")

async def main():
    """ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹œ ì¸ìë¥¼ íŒŒì‹±í•˜ê³  í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
    parser = argparse.ArgumentParser(description="Client for Intelligent Crypto Assistant MCP server.")
    parser.add_argument("--host", type=str, default="localhost", help="The hostname or IP address.")
    parser.add_argument("--port", type=int, default=8123, help="The port number of the MCP server.") 
    args = parser.parse_args()

    server_url = f"http://{args.host}:{args.port}"
    client = CryptoAssistantClient()

    try:
        await client.connect(server_url)
        await client.chat_loop()
    except KeyboardInterrupt:
        pass 
    except Exception as e:
        print(f"í´ë¼ì´ì–¸íŠ¸ ì‹œì‘ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        await client.cleanup()

if __name__ == "__main__":
    asyncio.run(main())